{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bupTUnUbugqp"
   },
   "outputs": [],
   "source": [
    "# import system libs\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "# import data handling tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# import Deep learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "\n",
    "# ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBmJup7svT9g"
   },
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "def loading_the_data(data_dir):\n",
    "    # Generate data paths with labels\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "\n",
    "    # Get folder names\n",
    "    folds = os.listdir(data_dir)\n",
    "\n",
    "    for fold in folds:\n",
    "        foldpath = os.path.join(data_dir, fold)\n",
    "        filelist = os.listdir(foldpath)\n",
    "        for file in filelist:\n",
    "            fpath = os.path.join(foldpath, file)\n",
    "\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(fold)\n",
    "\n",
    "    # Concatenate data paths with labels into one DataFrame\n",
    "    Fseries = pd.Series(filepaths, name='filepaths')\n",
    "    Lseries = pd.Series(labels, name='labels')\n",
    "\n",
    "    df = pd.concat([Fseries, Lseries], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# change label names to its original names\n",
    "def change_label_names(df, column_name):\n",
    "    index = {'blast': 'Blast', 'rust': 'Rust'}\n",
    "\n",
    "\n",
    "    df[column_name] = df[column_name].replace(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "dxTYBZO6vdLm",
    "outputId": "a1628c8b-03da-4800-b13c-48ed23700fc4"
   },
   "outputs": [],
   "source": [
    "# loading the data\n",
    "data_dir = r'C:\\Users\\kamis\\PycharmProjects\\Robotics\\.venv\\Files\\Dataset'\n",
    "df = loading_the_data(data_dir)\n",
    "\n",
    "change_label_names(df, 'labels')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "lCHHBzNevgGD",
    "outputId": "9fd3159f-76de-40b5-b3c3-326a85346ca4"
   },
   "outputs": [],
   "source": [
    "data_balance = df.labels.value_counts()\n",
    "\n",
    "\n",
    "def custom_autopct(pct):\n",
    "    total = sum(data_balance)\n",
    "    val = int(round(pct*total/100.0))\n",
    "    return \"{:.1f}%\\n({:d})\".format(pct, val)\n",
    "\n",
    "\n",
    "# pie chart for data balance\n",
    "plt.pie(data_balance, labels = data_balance.index, autopct=custom_autopct, colors = [\"#2092E6\",\"#6D8CE6\",\"#20D0E6\"])\n",
    "plt.title(\"Training data balance\")\n",
    "plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKe_XcFUxFj1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-x7WGVMAvg6K"
   },
   "outputs": [],
   "source": [
    "# data --> 80% train data && 20% (test, val)\n",
    "train_df, ts_df = train_test_split(df, train_size = 0.8, shuffle = True, random_state = 42)\n",
    "\n",
    "# test data --> 10% train data && 10% (test, val)\n",
    "valid_df, test_df = train_test_split(ts_df, train_size = 0.5, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KJZFZi52vitc",
    "outputId": "10521722-0e19-4a80-f284-16ca87528cd7"
   },
   "outputs": [],
   "source": [
    "# crobed image size\n",
    "batch_size = 32\n",
    "img_size = (224, 224)\n",
    "\n",
    "tr_gen = ImageDataGenerator(rescale=1. / 255)\n",
    "ts_gen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
    "                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
    "\n",
    "valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
    "                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
    "\n",
    "test_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
    "                                    color_mode= 'rgb', shuffle= False, batch_size= batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8tVmgUNExPe5",
    "outputId": "b656d05b-615c-450f-b06e-2ad367c6a22f"
   },
   "outputs": [],
   "source": [
    "g_dict = train_gen.class_indices      # defines dictionary {'class': index}\n",
    "classes = list(g_dict.keys())       # defines list of dictionary's kays (classes), classes names : string\n",
    "images, labels = next(train_gen)      # get a batch size samples from the generator\n",
    "\n",
    "# ploting the patch size samples\n",
    "plt.figure(figsize= (20, 20))\n",
    "\n",
    "for i in range(batch_size):\n",
    "    plt.subplot(6, 6, i + 1)\n",
    "    image = images[i]\n",
    "    plt.imshow(image)\n",
    "    index = np.argmax(labels[i])  # get image index\n",
    "    class_name = classes[index]   # get class of image\n",
    "    plt.title(class_name, color= 'black', fontsize= 16)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gXF7FIrMxTMO"
   },
   "outputs": [],
   "source": [
    "# Displaying the model performance\n",
    "def model_performance(history, Epochs):\n",
    "    # Define needed variables\n",
    "    tr_acc = history.history['accuracy']\n",
    "    tr_loss = history.history['loss']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    Epochs = [i+1 for i in range(len(tr_acc))]\n",
    "\n",
    "    # Plot training history\n",
    "    plt.figure(figsize= (20, 8))\n",
    "    plt.style.use('fivethirtyeight')\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
    "    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
    "    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "def model_evaluation(model):\n",
    "    train_score = model.evaluate(train_gen, verbose= 1)\n",
    "    valid_score = model.evaluate(valid_gen, verbose= 1)\n",
    "    test_score = model.evaluate(test_gen, verbose= 1)\n",
    "\n",
    "    print(\"Train Loss: \", train_score[0])\n",
    "    print(\"Train Accuracy: \", train_score[1])\n",
    "    print('-' * 20)\n",
    "    print(\"Validation Loss: \", valid_score[0])\n",
    "    print(\"Validation Accuracy: \", valid_score[1])\n",
    "    print('-' * 20)\n",
    "    print(\"Test Loss: \", test_score[0])\n",
    "    print(\"Test Accuracy: \", test_score[1])\n",
    "\n",
    "\n",
    "# Get Predictions\n",
    "def get_pred(model, test_gen):\n",
    "\n",
    "    preds = model.predict(test_gen)\n",
    "    y_pred = np.argmax(preds, axis = 1)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "def plot_confusion_matrix(test_gen, y_pred):\n",
    "\n",
    "    g_dict = test_gen.class_indices\n",
    "    classes = list(g_dict.keys())\n",
    "\n",
    "    # Display the confusion matrix\n",
    "    cm = confusion_matrix(test_gen.classes, y_pred)\n",
    "\n",
    "    plt.figure(figsize= (10, 10))\n",
    "    plt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation= 45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Defining a convolutional NN block for a sequential CNN model\n",
    "def conv_block(filters, act='relu'):\n",
    "\n",
    "    block = Sequential()\n",
    "    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n",
    "    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n",
    "    block.add(BatchNormalization())\n",
    "    block.add(MaxPooling2D())\n",
    "\n",
    "    return block\n",
    "\n",
    "\n",
    "# Defining a dense NN block for a sequential CNN model\n",
    "def dense_block(units, dropout_rate, act='relu'):\n",
    "\n",
    "    block = Sequential()\n",
    "    block.add(Dense(units, activation=act))\n",
    "    block.add(BatchNormalization())\n",
    "    block.add(Dropout(dropout_rate))\n",
    "\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6HO_CGJwvUC"
   },
   "outputs": [],
   "source": [
    "# create Model structure\n",
    "img_size = (224, 224)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "\n",
    "class_counts = len(list(train_gen.class_indices.keys()))     # to define number of classes in dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D36okQe0xY0n"
   },
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "cnn_model = Sequential()\n",
    "\n",
    "# first conv block\n",
    "cnn_model.add(Conv2D(filters=16, kernel_size=(3,3), padding=\"same\", activation=\"relu\", input_shape= img_shape))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(MaxPooling2D())\n",
    "\n",
    "# second conv block\n",
    "cnn_model.add(conv_block(32))\n",
    "\n",
    "# third conv block\n",
    "cnn_model.add(conv_block(64))\n",
    "\n",
    "# fourth conv bolck\n",
    "cnn_model.add(conv_block(128))\n",
    "\n",
    "# fifth conv block\n",
    "cnn_model.add(conv_block(256))\n",
    "\n",
    "# flatten layer\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "# first dense block\n",
    "cnn_model.add(dense_block(128, 0.5))\n",
    "\n",
    "# second dense block\n",
    "cnn_model.add(dense_block(64, 0.3))\n",
    "\n",
    "# third dense block\n",
    "cnn_model.add(dense_block(32, 0.2))\n",
    "\n",
    "# output layer\n",
    "cnn_model.add(Dense(class_counts, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQNZ3M1MxZ3G",
    "outputId": "6d7f8fbc-d49a-414d-ac7d-561c6d7ef80b"
   },
   "outputs": [],
   "source": [
    "cnn_model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "JVQcPE29xcYA",
    "outputId": "5638d4df-cc60-4d0a-ba15-4cba5eee5e64",
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m 85/125\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m50s\u001B[0m 1s/step - accuracy: 0.9314 - loss: 0.1898"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "epochs = 20   # number of all epochs in training\n",
    "\n",
    "history = cnn_model.fit(train_gen, epochs= epochs, verbose= 1, validation_data= valid_gen, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvPkbmETxdvH"
   },
   "outputs": [],
   "source": [
    "# Display model performance\n",
    "model_performance(history, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJKb9uyrxeip"
   },
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "model_evaluation(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSo2gSZTxfyZ"
   },
   "outputs": [],
   "source": [
    "# get predictions\n",
    "y_pred = get_pred(cnn_model, test_gen)\n",
    "\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(test_gen, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model evaluation results\n",
    "validation_loss = 0.15094275772571564\n",
    "validation_accuracy = 0.9444444179534912 * 100\n",
    "test_loss = 0.17059697210788727\n",
    "test_accuracy = 0.9445544481277466 * 100\n",
    "\n",
    "# Plotting the results\n",
    "labels = ['Validation', 'Test']\n",
    "loss_scores = [validation_loss, test_loss]\n",
    "acc_scores = [validation_accuracy, test_accuracy]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plotting Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(labels, loss_scores, color=['#FFA07A', '#20B2AA'], edgecolor='black', linewidth=0.5)\n",
    "plt.title('Loss Scores', fontsize=14)\n",
    "plt.xlabel('Data Split', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.gca().spines['top'].set_linewidth(0.5)\n",
    "plt.gca().spines['right'].set_linewidth(0.5)\n",
    "plt.gca().spines['bottom'].set_linewidth(0.5)\n",
    "plt.gca().spines['left'].set_linewidth(0.5)\n",
    "\n",
    "# Plotting Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(labels, acc_scores, color=['#FFA07A', '#20B2AA'], edgecolor='black', linewidth=0.5)\n",
    "plt.title('Accuracy Scores', fontsize=14)\n",
    "plt.xlabel('Data Split', fontsize=12)\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.ylim(60, 100)  # Set y-axis limit from 0 to 100\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.gca().spines['top'].set_linewidth(0.5)\n",
    "plt.gca().spines['right'].set_linewidth(0.5)\n",
    "plt.gca().spines['bottom'].set_linewidth(0.5)\n",
    "plt.gca().spines['left'].set_linewidth(0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Accuracy scores for training, validation, and test\n",
    "training_accuracy = 97.47\n",
    "validation_accuracy = 94.44\n",
    "test_accuracy = 94.46\n",
    "\n",
    "# Plotting the results\n",
    "labels = ['Training', 'Validation', 'Test']\n",
    "accuracy_scores = [training_accuracy, validation_accuracy, test_accuracy]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plotting Accuracy\n",
    "x = np.arange(len(labels))  # Positions for bars (default)\n",
    "bar_width = 0.25\n",
    "\n",
    "# Option 1: Using plt.xticks alignment argument\n",
    "# plt.bar(x - bar_width / 2, accuracy_scores, bar_width, color=['#FFA07A', '#20B2AA', '#6495ED'], edgecolor='black', linewidth=0.5)\n",
    "# plt.xticks(x - bar_width / 2, labels, fontsize=10, alignment='center')  # Centered labels\n",
    "\n",
    "# Option 2: Manually adjusting x-axis position\n",
    "plt.bar(x, accuracy_scores, bar_width, color=['#FFA07A', '#20B2AA', '#6495ED'], edgecolor='black', linewidth=0.5)\n",
    "num_bars = len(labels)\n",
    "bar_positions = np.arange(num_bars)  # Create positions\n",
    "plt.xticks(bar_positions, labels, fontsize=10)  # Set xticks at bar positions\n",
    "\n",
    "plt.title('Model Accuracy', fontsize=14)\n",
    "plt.xlabel('Data Split', fontsize=12)\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.ylim(70, 100)  # Set y-axis limit from 0 to 100\n",
    "plt.gca().spines['top'].set_linewidth(0.5)\n",
    "plt.gca().spines['right'].set_linewidth(0.5)\n",
    "plt.gca().spines['bottom'].set_linewidth(0.5)\n",
    "plt.gca().spines['left'].set_linewidth(0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "Y_pred = EfficientNetB3_model.predict(test_gen)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "# Convert class labels from one-hot encoding to original labels\n",
    "encoder = LabelEncoder()\n",
    "true_labels = encoder.fit_transform(test_gen.classes)\n",
    "predicted_labels = y_pred\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(true_labels, predicted_labels, target_names=test_gen.class_indices.keys(), output_dict=True)\n",
    "\n",
    "# Extract metrics for each class\n",
    "classes = list(report.keys())[:-3]  # Exclude 'accuracy', 'macro avg', and 'weighted avg'\n",
    "metrics = ['precision', 'recall', 'f1-score']\n",
    "scores = np.zeros((len(classes), len(metrics)))\n",
    "\n",
    "for i, class_ in enumerate(classes):\n",
    "    for j, metric in enumerate(metrics):\n",
    "        scores[i, j] = report[class_][metric]\n",
    "\n",
    "# Plotting the classification report as a bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.2\n",
    "index = np.arange(len(classes))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.bar(index + i * bar_width, scores[:, i], bar_width, label=metric)\n",
    "\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Classification Report')\n",
    "plt.xticks(index + bar_width, classes, rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Classification metrics for the alternative model\n",
    "alternative_metrics = {\n",
    "   \n",
    "    'Precision': 0.88,\n",
    "    'Recall': 0.91,\n",
    "    'F1-Score': 0.89\n",
    "}\n",
    "\n",
    "# Classification metrics for your model (EfficientNet)\n",
    "your_model_metrics = {\n",
    "    \n",
    "    'Precision': 0.95,\n",
    "    'Recall': 0.94,\n",
    "    'F1-Score': 0.94\n",
    "}\n",
    "\n",
    "# Labels for the classification metrics\n",
    "metrics_labels = list(alternative_metrics.keys())\n",
    "\n",
    "# Set the width of the bars\n",
    "bar_width = 0.35\n",
    "\n",
    "# Set the position of the bars on the x-axis\n",
    "x = np.arange(len(metrics_labels))\n",
    "\n",
    "# Plotting the grouped bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.bar(x - bar_width/2, list(alternative_metrics.values()), bar_width, label='CNN +LR')\n",
    "plt.bar(x + bar_width/2, list(your_model_metrics.values()), bar_width, label='Our Model (EfficientNet+SVM)')\n",
    "\n",
    "# Adding labels, title, and legend\n",
    "plt.xlabel('Classification Metric', fontsize=12)\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.title('Comparison of Classification Metrics', fontsize=14)\n",
    "plt.xticks(x, metrics_labels)\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cnp8Bwfevwtg"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))  # Adjust the figure size as needed\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Get predictions\n",
    "y_pred = get_pred(EfficientNetB3_model, test_gen)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_gen.classes, y_pred)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=test_gen.class_indices.keys(),\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
